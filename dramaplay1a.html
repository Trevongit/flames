<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Drama: A Spark in the Dark</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tone/14.7.77/Tone.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Cutive+Mono&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #111827;
            color: #F3F4F6;
        }
        .script-font {
            font-family: 'Cutive Mono', monospace;
        }
        .highlight {
            background-color: rgba(251, 191, 36, 0.2);
            transition: background-color 0.3s ease;
        }
        .loader {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #fbbf24;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        #script-display {
            max-height: 80vh; /* Use viewport height for flexibility */
            min-height: 20rem;
        }
    </style>
</head>
<body class="flex items-center justify-center min-h-screen bg-gray-900">
    <div class="w-full max-w-3xl mx-auto p-4 sm:p-6 md:p-8 bg-gray-800 rounded-2xl shadow-2xl border border-gray-700">
        <header class="text-center mb-6">
            <h1 class="text-2xl sm:text-3xl font-bold text-amber-300">The Flame We Nurture</h1>
            <p class="text-lg sm:text-xl text-gray-300">Chapter 1: A Spark in the Dark</p>
        </header>

        <div id="script-display" class="script-font bg-gray-900/50 rounded-lg p-4 sm:p-6 overflow-y-auto border border-gray-700 mb-6 text-gray-300 text-sm sm:text-base">
            <!-- Script lines will be injected here -->
        </div>

        <div id="controls" class="flex flex-col items-center space-y-4">
            <div id="player-ui" class="w-full">
                <div class="flex items-center justify-center space-x-4 mb-4">
                    <button id="play-pause-btn"
                            class="bg-amber-400 hover:bg-amber-500 text-gray-900 font-bold p-4 rounded-full shadow-lg transition-transform transform hover:scale-105 focus:outline-none focus:ring-2 focus:ring-amber-300"
                            aria-label="Play or pause audio drama">
                        <svg id="play-icon" xmlns="http://www.w3.org/2000/svg" class="h-8 w-8" viewBox="0 0 20 20" fill="currentColor">
                            <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM9.555 7.168A1 1 0 008 8v4a1 1 0 001.555.832l3-2a1 1 0 000-1.664l-3-2z" clip-rule="evenodd" />
                        </svg>
                        <svg id="pause-icon" xmlns="http://www.w3.org/2000/svg" class="h-8 w-8 hidden" viewBox="0 0 20 20" fill="currentColor">
                            <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8 7a1 1 0 00-1 1v4a1 1 0 102 0V8a1 1 0 00-1-1zm4 0a1 1 0 00-1 1v4a1 1 0 102 0V8a1 1 0 00-1-1z" clip-rule="evenodd" />
                        </svg>
                    </button>
                </div>
                <div id="progress-container" class="w-full bg-gray-700 rounded-full h-2.5 mb-4 cursor-pointer">
                    <div id="progress-bar" class="bg-amber-400 h-2.5 rounded-full" style="width: 0%"></div>
                </div>

                <div class="flex items-center justify-between w-full space-x-4 mb-4">
                    <label for="volume-control" class="text-gray-300 text-sm">Volume:</label>
                    <input type="range" id="volume-control" min="0" max="1" step="0.05" value="0.75" class="w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer range-amber">
                    <style>
                        .range-amber::-webkit-slider-thumb {
                            background-color: #fbbf24;
                        }
                        .range-amber::-moz-range-thumb {
                            background-color: #fbbf24;
                        }
                    </style>
                </div>

                <div class="flex items-center justify-between w-full space-x-4">
                    <label for="speed-control" class="text-gray-300 text-sm">Speed:</label>
                    <select id="speed-control" class="bg-gray-700 border border-gray-600 text-gray-300 text-sm rounded-lg focus:ring-amber-500 focus:border-amber-500 block p-2.5">
                        <option value="1.0">1x</option>
                        <option value="1.25">1.25x</option>
                        <option value="1.5">1.5x</option>
                        <option value="2.0">2x</option>
                    </select>
                </div>

            </div>
            <div id="loading-indicator" class="hidden flex-col items-center space-y-2">
                <div class="loader"></div>
                <p id="loading-text" class="text-amber-300">Generating audio, please wait...</p>
            </div>
            <div id="error-message" class="hidden text-red-400 text-center"></div>
        </div>
    </div>

    <script type="module">
        // --- Main Application Logic ---
        const scriptDisplay = document.getElementById('script-display');
        const playPauseBtn = document.getElementById('play-pause-btn');
        const playIcon = document.getElementById('play-icon');
        const pauseIcon = document.getElementById('pause-icon');
        const progressBar = document.getElementById('progress-bar');
        const progressContainer = document.getElementById('progress-container');
        const loadingIndicator = document.getElementById('loading-indicator');
        const loadingText = document.getElementById('loading-text');
        const playerUI = document.getElementById('player-ui');
        const errorMessage = document.getElementById('error-message');
        const volumeControl = document.getElementById('volume-control');
        const speedControl = document.getElementById('speed-control');

        let audioContext;
        let isPlaying = false;
        let currentAudio = null; // Reference to the currently playing HTMLAudioElement
        let currentTonePlayer = null; // Reference to the currently playing Tone.Player
        let currentLineIndex = 0;
        let audioQueue = []; // Stores structured objects: { type: 'speech', url, speaker, duration } or { type: 'sfx', sound, duration }
        let sfx = {};
        let isGenerating = false;
        let totalDramaDuration = 0; // Total duration of all playable items in seconds
        let elapsedDramaDuration = 0; // Elapsed duration for progress bar

        // --- Script Definition ---
        const script = [
            // Pre-recorded Introduction Music/Narration
            { type: 'static_audio', url: 'https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3', duration: 10, description: 'Introductory Music' },
            { type: 'music', action: 'start', mood: 'tense', duration: 5 }, // Estimated duration for non-TTS items
            { speaker: 'NARRATOR', line: "The city is a skeleton, picked clean by time." },
            { type: 'sfx', action: 'start', sound: 'wind', duration: 3 },
            { speaker: 'NARRATOR', line: "A hollow wind howls through the decaying remains of once-thriving buildings, and the flickering neon signs that still cling to life cast a broken reflection in the puddles below." },
            { type: 'sfx', action: 'start', sound: 'drips', duration: 4 },
            { speaker: 'NARRATOR', line: "Deep within this urban graveyard lies the cavernous, shadowed terminal of an abandoned train station." },
            { speaker: 'NARRATOR', line: "Here, where ivy strangles cracked pillars and dust dances in the stale air, a single spark of light appears." },
            { type: 'sfx', action: 'play', sound: 'matchStrike', duration: 0.5 },
            { speaker: 'AUREN', line: "Just a little longer.", style: 'muttering, anxious' },
            { type: 'sfx', action: 'start', sound: 'footsteps', duration: 2 },
            { speaker: 'NARRATOR', line: "A sound. Auren whirls, his breath catching in his throat." },
            { type: 'sfx', action: 'play', sound: 'lampOut', duration: 1 },
            { type: 'sfx', action: 'stop', sound: 'footsteps', duration: 0 },
            { speaker: 'ZIVAH', line: "If you’re trying to disappear, you’re doing a terrible job.", style: 'clear, confident' },
            { type: 'sfx', action: 'play', sound: 'pipeDrop', duration: 1 },
            { speaker: 'AUREN', line: "You followed me.", style: 'relieved but annoyed' },
            { speaker: 'ZIVAH', line: "You left a trail of smoldering breadcrumbs." },
            { speaker: 'AUREN', line: "It’s not safe." },
            { speaker: 'ZIVAH', line: "Since when has that stopped you?", style: 'smirking' },
            { speaker: 'AUREN', line: "I felt... something. In the air. Like...", style: 'serious' },
            { type: 'sfx', action: 'play', sound: 'thunder', duration: 3 },
            { speaker: 'ZIVAH', line: "The Surge?", style: 'serious' },
            { speaker: 'AUREN', line: "It’s building again." },
            { type: 'sfx', action: 'start', sound: 'hum', duration: 5 },
            { speaker: 'ZIVAH', line: "That’s not wind.", style: 'alarmed' },
            { speaker: 'AUREN', line: "It’s waking up again. The Old Sparks... the map led here. The glyphs confirm it." },
            { type: 'sfx', action: 'play', sound: 'panelOpen', duration: 2 },
            { speaker: 'NARRATOR', line: "A hidden panel slides away, revealing a staircase spiraling down into deeper darkness." },
            { speaker: 'NARRATOR', line: "As they descend, the hum grows louder—a metallic, unnatural pulse, like the beating of a mechanical heart." },
            { type: 'music', action: 'swell', duration: 5 },
            { type: 'sfx', action: 'stop', sound: 'all', duration: 0 },
            { type: 'music', action: 'stop', duration: 0 }
        ];

        // --- Voice & Sound Configuration ---
        const voiceConfig = {
            'NARRATOR': { voiceName: 'Charon' },
            'AUREN': { voiceName: 'Leda' },
            'ZIVAH': { voiceName: 'Kore' },
            'VAEL': { voiceName: 'Gacrux' },
            'ENFORCER': { voiceName: 'Orus' }
        };

        // --- Utility Functions ---
        function showError(message) {
            errorMessage.textContent = message;
            errorMessage.classList.remove('hidden');
            loadingIndicator.classList.add('hidden');
            playerUI.classList.remove('hidden');
            isGenerating = false;
        }

        function base64ToArrayBuffer(base64) {
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }
        
        function pcmToWav(pcmData, sampleRate) {
            const numChannels = 1;
            const bytesPerSample = 2;
            const blockAlign = numChannels * bytesPerSample;
            const byteRate = sampleRate * blockAlign;
            const dataSize = pcmData.length * bytesPerSample;
            const buffer = new ArrayBuffer(44 + dataSize);
            const view = new DataView(buffer);

            function writeString(view, offset, string) {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            }

            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + dataSize, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true); // PCM
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, byteRate, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, 16, true); // 16-bit
            writeString(view, 36, 'data');
            view.setUint32(40, dataSize, true);

            let offset = 44;
            for (let i = 0; i < pcmData.length; i++, offset += 2) {
                view.setInt16(offset, pcmData[i], true);
            }

            return new Blob([view], { type: 'audio/wav' });
        }

        // --- Tone.js Sound Effect Management ---
        async function initializeSFX() {
            try {
                if (Tone.context.state !== 'running') {
                    await Tone.start();
                }
                sfx.wind = new Tone.Noise('brown').set({ volume: -30, fadeOut: 2 }).toDestination();
                sfx.drips = new Tone.MembraneSynth({
                    pitchDecay: 0.05,
                    octaves: 10,
                    oscillator: { type: 'sine' },
                    envelope: { attack: 0.001, decay: 0.4, sustain: 0.01, release: 1.4, attackCurve: 'exponential' }
                }).toDestination();
                sfx.hum = new Tone.AMOscillator('F#2', 'sine', 'sine').set({ volume: -25, harmonicity: 0.5 }).toDestination();
                sfx.music = new Tone.PolySynth(Tone.Synth, {
                    oscillator: { type: "amsine", harmonicity: 1.01 },
                    envelope: { attack: 0.1, decay: 0.2, sustain: 0.5, release: 2 },
                    volume: -15
                }).toDestination();
                sfx.reverb = new Tone.Reverb({ decay: 4, wet: 0.4 }).toDestination();
            } catch (error) {
                console.error("Failed to initialize Tone.js SFX:", error);
                showError("Audio system failed to initialize. Please ensure your browser allows audio playback.");
            }
        }

        function disposeSFX() {
            Object.values(sfx).forEach(node => {
                if (node.stop) node.stop();
                if (node.dispose) node.dispose();
            });
            if (sfx.dripsLoop) {
                sfx.dripsLoop.stop().dispose();
                delete sfx.dripsLoop;
            }
            Tone.Transport.stop();
            sfx = {}; // Reset sfx object
        }

        function handleSfx(action, sound) {
            if (!Tone.context || Tone.context.state !== 'running') {
                 console.warn("Tone.js AudioContext not running. SFX not played.");
                 return;
            }
            switch (sound) {
                case 'wind':
                    action === 'start' ? sfx.wind.start() : sfx.wind.stop();
                    break;
                case 'drips':
                    if (action === 'start' && !sfx.dripsLoop) {
                        sfx.dripsLoop = new Tone.Loop(time => {
                            sfx.drips.triggerAttackRelease('C4', '8n', time);
                        }, "2.5s").start(0);
                        Tone.Transport.start();
                    } else if (action === 'stop' && sfx.dripsLoop) {
                        sfx.dripsLoop.stop().dispose();
                        delete sfx.dripsLoop;
                    }
                    break;
                case 'hum':
                    action === 'start' ? sfx.hum.start() : sfx.hum.stop();
                    break;
                case 'matchStrike':
                    const noiseSynth = new Tone.NoiseSynth({ noise: { type: 'white' }, envelope: { attack: 0.001, decay: 0.1, sustain: 0 } }).toDestination();
                    noiseSynth.triggerAttackRelease("0.1");
                    break;
                case 'lampOut':
                    const windSynth = new Tone.NoiseSynth({ noise: { type: 'pink' }, envelope: { attack: 0.01, decay: 0.2, sustain: 0.1, release: 0.2 } }).toDestination();
                    windSynth.triggerAttackRelease("0.3");
                    break;
                case 'pipeDrop':
                    const metalSynth = new Tone.MembraneSynth({ pitchDecay: 0.1, octaves: 2, envelope: { attack: 0.001, decay: 0.5, release: 1 } }).toDestination();
                    metalSynth.triggerAttackRelease("C2", "8n");
                    break;
                case 'thunder':
                    const thunderNoise = new Tone.Noise('brown').set({ volume: -10, fadeOut: 3 }).toDestination();
                    thunderNoise.start().stop("+3");
                    break;
                case 'panelOpen':
                    const panelNoise = new Tone.NoiseSynth({ noise: { type: 'white' }, envelope: { attack: 0.1, decay: 1.5, sustain: 0.2, release: 0.5 } }).toDestination();
                    panelNoise.triggerAttackRelease("1.5");
                    break;
                case 'all':
                    disposeSFX(); // Use the new dispose function
                    break;
            }
        }
        
        function handleMusic(action, mood) {
            if (!Tone.context || Tone.context.state !== 'running') {
                 console.warn("Tone.js AudioContext not running. Music not played.");
                 return;
            }
            if (action === 'start') {
                sfx.music.triggerAttackRelease(['C2', 'G2', 'Eb3'], '8n');
            } else if (action === 'swell') {
                sfx.music.triggerAttackRelease(['F#2', 'C#3', 'A3'], '4n');
            } else if (action === 'stop') {
                // Music fades out naturally via release
                if (sfx.music) sfx.music.releaseAll();
            }
        }

        // --- Audio Generation (Gemini API) ---
        async function getAudioDuration(audioUrl) {
            return new Promise(resolve => {
                const audio = new Audio(audioUrl);
                audio.onloadedmetadata = () => {
                    resolve(audio.duration);
                };
                audio.onerror = () => {
                    console.error("Failed to load audio metadata for duration calculation:", audioUrl);
                    resolve(0); // Return 0 if duration cannot be determined
                };
            });
        }

        // Helper function for safe Base64 encoding
        function safeBtoa(str) {
            return btoa(encodeURIComponent(str).replace(/%([0-9A-F]{2})/g,
                function toSolidBytes(match, p1) {
                    return String.fromCharCode('0x' + p1);
                }));
        }

        async function generateAudio(text, speaker, index) {
            // Local storage key for caching, using safeBtoa
            const cacheKey = `audiocache_${speaker}_${safeBtoa(text)}`; 

            // Try to load from cache first
            const cachedData = localStorage.getItem(cacheKey);
            if (cachedData) {
                console.log(`Loading audio for line ${index} from cache.`);
                const parsedData = JSON.parse(cachedData);
                return { url: parsedData.url, duration: parsedData.duration };
            }


            const apiKey = "AIzaSyCX19N3c_Kgxh42bMdz9xEZKu9rgQebQ04"; // Using your provided API key
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;
            
            const selectedVoiceConfig = voiceConfig[speaker] || { voiceName: 'Kore' };

            const payload = {
                contents: [{ parts: [{ text: text }] }],
                generationConfig: {
                    responseModalities: ["AUDIO"],
                    speechConfig: {
                        voiceConfig: {
                            prebuiltVoiceConfig: {
                                voiceName: selectedVoiceConfig.voiceName
                            }
                        }
                    }
                },
                model: "gemini-2.5-flash-preview-tts"
            };
            
            console.log(`API Request for line ${index} - URL:`, apiUrl);
            console.log(`API Request for line ${index} - Payload:`, JSON.stringify(payload, null, 2));

            let response;
            let delay = 1000;
            const maxRetries = 5;

            for (let i = 0; i < maxRetries; i++) {
                try {
                    response = await fetch(apiUrl, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });

                    if (response.ok) {
                        break;
                    } else {
                        let errorBody = '';
                        try {
                            errorBody = await response.text();
                            const jsonAttempt = JSON.parse(errorBody);
                            errorBody = jsonAttempt;
                        } catch (parseError) {}

                        console.error(`Attempt ${i + 1} for line ${index}: API Error: ${response.status} ${response.statusText}`, errorBody);

                        if (response.status === 429) {
                            console.warn(`Attempt ${i + 1} for line ${index}: Rate limit hit. Retrying in ${delay / 1000}s...`);
                        } else {
                            throw new Error(`API request failed with status ${response.status} for line ${index}: ${typeof errorBody === 'object' ? JSON.stringify(errorBody) : errorBody}`);
                        }
                    }
                } catch (fetchError) {
                    console.error(`Attempt ${i + 1} for line ${index}: Fetch error:`, fetchError);
                    if (i === maxRetries - 1) {
                        throw new Error(`Failed to fetch from API after ${maxRetries} retries for line ${index}: ${fetchError.message}`);
                    }
                }
                await new Promise(resolve => setTimeout(resolve, delay));
                delay *= 2;
            }

            if (!response || !response.ok) {
                throw new Error(`Failed to get a successful API response after multiple retries for line ${index}.`);
            }

            const resultText = await response.text();
            let result;
            try {
                result = JSON.parse(resultText);
            } catch (jsonParseError) {
                console.error(`Failed to parse API response as JSON for line ${index}:`, resultText, jsonParseError);
                throw new Error("Invalid JSON response from API.");
            }
            
            const part = result?.candidates?.[0]?.content?.parts?.[0];
            const audioData = part?.inlineData?.data;
            const mimeType = part?.inlineData?.mimeType;

            if (audioData && mimeType && mimeType.startsWith("audio/L16")) {
                const match = mimeType.match(/rate=(\d+)/);
                const sampleRate = match ? parseInt(match[1], 10) : 16000;

                const pcmBuffer = base64ToArrayBuffer(audioData);
                const pcm16 = new Int16Array(pcmBuffer);
                const wavBlob = pcmToWav(pcm16, sampleRate);
                const audioUrl = URL.createObjectURL(wavBlob);

                const duration = await getAudioDuration(audioUrl); // Get actual audio duration

                // Cache the generated audio URL and its duration
                localStorage.setItem(cacheKey, JSON.stringify({ url: audioUrl, duration: duration }));

                return { url: audioUrl, duration: duration };
            } else {
                console.error("Unexpected API response structure or mimeType for line:", index, result);
                throw new Error("Failed to extract expected 'audio/L16' data from API response. Response details: " + JSON.stringify(result));
            }
        }
        
        // --- Playback Logic ---
        function pausePlayback() {
            if (currentAudio) {
                currentAudio.pause();
            }
            if (currentTonePlayer && currentTonePlayer.state === 'started') {
                 currentTonePlayer.stop(); // Stop Tone.Player for SFX
            }
            // Stop any active Tone.js loops/sounds that are continuous
            if (sfx.dripsLoop && sfx.dripsLoop.state === 'started') sfx.dripsLoop.stop();
            if (sfx.wind && sfx.wind.state === 'started') sfx.wind.stop();
            if (sfx.hum && sfx.hum.state === 'started') sfx.hum.stop();
            if (sfx.music && sfx.music.state === 'started') sfx.music.releaseAll(); // Fade out music
        }


        async function playNextLine() {
            if (currentLineIndex >= audioQueue.length || !isPlaying) {
                isPlaying = false;
                updatePlayPauseButton();
                disposeSFX(); // Clean up all Tone.js resources
                currentAudio = null;
                currentTonePlayer = null;
                // Optionally reset progress and index when done
                elapsedDramaDuration = totalDramaDuration;
                updateProgressBar();
                return;
            }

            const currentItem = audioQueue[currentLineIndex];
            if (!currentItem) { // Handle non-playable items (e.g., music/sfx placeholders if not processed by Tone.js)
                 currentLineIndex++;
                 playNextLine();
                 return;
            }

            highlightCurrentLine();
            updateProgressBar();

            if (currentItem.type === 'speech' || currentItem.type === 'static_audio') { // Combined handling
                currentAudio = new Audio(currentItem.url);
                currentAudio.playbackRate = parseFloat(speedControl.value);
                currentAudio.volume = parseFloat(volumeControl.value);
                
                currentAudio.play();

                let lastTimeUpdate = 0;
                currentAudio.ontimeupdate = () => {
                    const currentTime = currentAudio.currentTime;
                    elapsedDramaDuration += (currentTime - lastTimeUpdate);
                    lastTimeUpdate = currentTime;
                    updateProgressBar();
                };

                currentAudio.onended = () => {
                    // Only revoke object URL for dynamically generated audio (not static_audio if it's external)
                    if (currentItem.type === 'speech') {
                       URL.revokeObjectURL(currentItem.url); 
                    }
                    currentLineIndex++;
                    elapsedDramaDuration += (currentItem.duration - lastTimeUpdate);
                    lastTimeUpdate = 0;
                    playNextLine();
                };

            } else if (currentItem.type === 'sfx' || currentItem.type === 'music') {
                // For SFX/Music handled by Tone.js, play them and then immediately advance
                // Note: Complex SFX/Music with exact durations would need more sophisticated scheduling
                if (currentItem.type === 'sfx') {
                    handleSfx(currentItem.action, currentItem.sound);
                } else if (currentItem.type === 'music') {
                    handleMusic(currentItem.action, currentItem.mood);
                }
                
                // For SFX/Music, advance immediately after handling the event
                // If it has a specific duration, we add that to elapsed and then move
                elapsedDramaDuration += currentItem.duration || 0; // Add duration, default to 0 if not set
                updateProgressBar();
                currentLineIndex++;
                await new Promise(resolve => setTimeout(resolve, (currentItem.duration || 0) * 1000 / parseFloat(speedControl.value))); // Wait for sfx/music duration if any
                playNextLine();
            }
        }

        async function pregenerateAllAudio() {
            if (isGenerating) return;
            isGenerating = true;
            loadingIndicator.classList.remove('hidden');
            playerUI.classList.add('hidden');
            errorMessage.classList.add('hidden');
            currentLineIndex = 0; // Reset index for full regeneration
            audioQueue = []; // Clear previous queue
            totalDramaDuration = 0;
            elapsedDramaDuration = 0;
            updateProgressBar();

            const speechLinesToGenerate = script.filter(item => item.speaker).length;
            let generatedSpeechLines = 0;

            try {
                for (let i = 0; i < script.length; i++) {
                    const item = script[i];

                    if (item.type === 'static_audio') {
                        loadingText.textContent = `Loading introductory audio...`;
                        const audioUrl = item.url;
                        const duration = await getAudioDuration(audioUrl);
                        audioQueue[i] = { type: 'static_audio', url: audioUrl, duration: duration, description: item.description };
                        totalDramaDuration += duration;
                    } else if (item.speaker && item.line) {
                        loadingText.textContent = `Generating audio (${++generatedSpeechLines}/${speechLinesToGenerate})...`;
                        const textToGenerate = item.style ? `Say in a ${item.style} tone: ${item.line}` : item.line;
                        const audioInfo = await generateAudio(textToGenerate, item.speaker, i); // returns {url, duration}
                        audioQueue[i] = { type: 'speech', ...audioInfo, speaker: item.speaker };
                        totalDramaDuration += audioInfo.duration;
                    } else if (item.type === 'sfx' || item.type === 'music') {
                        audioQueue[i] = { type: item.type, sound: item.sound, mood: item.mood, action: item.action, duration: item.duration || 0 };
                        totalDramaDuration += item.duration || 0;
                    } else {
                        audioQueue[i] = null; // Mark as non-playable/non-generating
                    }
                    // Small delay to allow UI to update and avoid hammering if generating many fast lines
                    await new Promise(resolve => setTimeout(resolve, 50));
                }
                
                isGenerating = false;
                loadingIndicator.classList.add('hidden');
                playerUI.classList.remove('hidden');
                
                isPlaying = true; // Auto-start after generation
                updatePlayPauseButton();
                playNextLine();

            } catch (error) {
                console.error("Error during audio generation in pregenerateAllAudio:", error);
                showError(`Could not generate audio: ${error.message}. Please check console for details.`);
                isGenerating = false;
                loadingIndicator.classList.add('hidden');
                playerUI.classList.remove('hidden');
            }
        }
        
        // --- UI Updates ---
        function updatePlayPauseButton() {
            if (isPlaying) {
                playIcon.classList.add('hidden');
                pauseIcon.classList.remove('hidden');
            } else {
                playIcon.classList.remove('hidden');
                pauseIcon.classList.add('hidden');
            }
        }

        function highlightCurrentLine() {
            document.querySelectorAll('.script-line').forEach((el) => {
                if (parseInt(el.dataset.index) === currentLineIndex) {
                    el.classList.add('highlight');
                    el.scrollIntoView({ behavior: 'smooth', block: 'center' });
                } else {
                    el.classList.remove('highlight');
                }
            });
        }
        
        function updateProgressBar() {
            if (totalDramaDuration > 0) {
                const progress = (elapsedDramaDuration / totalDramaDuration) * 100;
                progressBar.style.width = `${Math.min(100, Math.max(0, progress))}%`;
            } else {
                progressBar.style.width = '0%';
            }
        }

        function populateScriptDisplay() {
            scriptDisplay.innerHTML = ''; // Clear previous content
            script.forEach((item, index) => {
                if (item.speaker) {
                    const lineEl = document.createElement('div');
                    lineEl.classList.add('script-line', 'mb-3');
                    lineEl.dataset.index = index;

                    const speakerEl = document.createElement('strong');
                    speakerEl.classList.add('text-amber-300');
                    speakerEl.textContent = `${item.speaker}: `;
                    
                    const textEl = document.createElement('span');
                    textEl.textContent = item.line;

                    lineEl.appendChild(speakerEl);
                    lineEl.appendChild(textEl);
                    scriptDisplay.appendChild(lineEl);
                } else if (item.type === 'sfx' || item.type === 'music') {
                    const sfxEl = document.createElement('div');
                    sfxEl.classList.add('script-line', 'text-gray-500', 'italic', 'my-2', 'text-center');
                    sfxEl.dataset.index = index;
                    sfxEl.textContent = `[${item.type.toUpperCase()}: ${item.action} ${item.sound || item.mood || ''}]`;
                    scriptDisplay.appendChild(sfxEl);
                } else if (item.type === 'static_audio') { // New: static audio line
                    const staticAudioEl = document.createElement('div');
                    staticAudioEl.classList.add('script-line', 'text-gray-500', 'italic', 'my-2', 'text-center');
                    staticAudioEl.dataset.index = index;
                    staticAudioEl.textContent = `[INTRO: ${item.description}]`;
                    scriptDisplay.appendChild(staticAudioEl);
                }
            });
        }
        
        // --- Event Listeners ---
        playPauseBtn.addEventListener('click', async () => {
            // Initialize Tone.js and SFX on first user interaction
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                await initializeSFX();
            }

            if (isGenerating) return;

            if (!isPlaying && (audioQueue.length === 0 || currentLineIndex >= audioQueue.length)) {
                // If not playing and either no audio generated or reached end, start generation
                currentLineIndex = 0; // Reset for new playback
                elapsedDramaDuration = 0;
                pregenerateAllAudio();
            } else {
                isPlaying = !isPlaying;
                updatePlayPauseButton();
                if (isPlaying) {
                    playNextLine();
                } else {
                    pausePlayback();
                    console.log("Playback paused.");
                }
            }
        });

        volumeControl.addEventListener('input', (e) => {
            const volume = parseFloat(e.target.value);
            // Apply to Tone.js master output
            if (Tone.Master) {
                Tone.Master.volume.value = Tone.gainToDb(volume);
            }
            // Apply to currently playing HTMLAudioElement if any
            if (currentAudio) {
                currentAudio.volume = volume;
            }
        });

        speedControl.addEventListener('change', (e) => {
            const speed = parseFloat(e.target.value);
            if (currentAudio) {
                currentAudio.playbackRate = speed;
            }
            // Tone.js playback rate for Players would need to be handled if used
        });

        progressContainer.addEventListener('click', (e) => {
            if (isGenerating || audioQueue.length === 0) return;

            const rect = progressContainer.getBoundingClientRect();
            const clickX = e.clientX - rect.left;
            const clickProgress = clickX / rect.width; // 0 to 1

            let seekTime = clickProgress * totalDramaDuration;
            
            // Find the closest line to seekTime
            let accumulatedDuration = 0;
            let targetLineIndex = 0;
            for (let i = 0; i < audioQueue.length; i++) {
                const item = audioQueue[i];
                if (item && item.duration) {
                    accumulatedDuration += item.duration;
                }
                if (accumulatedDuration >= seekTime) {
                    targetLineIndex = i;
                    break;
                }
                targetLineIndex = i; // Default to last line if seeking beyond calculated duration
            }

            // Stop current playback
            pausePlayback();
            isPlaying = true;
            updatePlayPauseButton();

            // Reset current line index and recalculate elapsed duration up to the target line
            currentLineIndex = targetLineIndex;
            elapsedDramaDuration = 0;
            for (let i = 0; i < currentLineIndex; i++) {
                const item = audioQueue[i];
                if (item && item.duration) {
                    elapsedDramaDuration += item.duration;
                }
            }
            // If seeking mid-speech line, calculate the offset
            if (audioQueue[currentLineIndex] && (audioQueue[currentLineIndex].type === 'speech' || audioQueue[currentLineIndex].type === 'static_audio') && accumulatedDuration > seekTime) {
                const previousItemsDuration = accumulatedDuration - audioQueue[currentLineIndex].duration;
                const offsetInCurrentLine = seekTime - previousItemsDuration;
                if (offsetInCurrentLine > 0) {
                    // For now, seeking jumps to the start of the closest line.
                    console.warn("Seeking within an audio line is not precisely supported; starting from the beginning of the closest line.");
                    elapsedDramaDuration -= (audioQueue[currentLineIndex].duration - offsetInCurrentLine);
                }
            }
            
            playNextLine();
        });


        // --- Initialization ---
        window.onload = () => {
            populateScriptDisplay();
            updateProgressBar();
            // Set initial Tone.js master volume
            if (Tone.Master) {
                Tone.Master.volume.value = Tone.gainToDb(parseFloat(volumeControl.value));
            }
        };

    </script>
</body>
</html>
